<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>analysis.utf8.md</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />
<link href="https://fonts.googleapis.com/css?family=Nunito+Sans|Roboto|Lobster" rel="stylesheet">

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">
      	<img alt="Nemabiome Logo" src="images/logo/nemabiome_compact_64.png" style="width:35px;height:35px">
      </a>
    </div>
    	
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
				
				<li>
					<a href="overview.html">
						<span class="ion ion-map"></span>
    				Overview
					</a>
				</li>
	
			<!-- Parasite -->
				<li>
  				<a href="parasite.html">
    				<span class="ion ion-bug"></span>
    				Parasite Prep
     			</a>
				</li>
				
			<!-- Sequencing -->	
				<li>
  				<a href="sequencing.html">
    				<span class="ion ion-erlenmeyer-flask"></span>
    				Sequencing
     			</a>
				</li>
				
			<!-- Analysis -->
				<li>
  				<a href="analysis.html">
    				<span class="ion ion-monitor"></span>
    				Analysis
     			</a>
				</li>
			
			<!-- Interpretation -->
				<li>
  				<a href="interpretation.html">
    				<span class="ion ion-stats-bars"></span>
    				Interpretation
     			</a>
				</li>

			</ul>
			
			<!-- Citation and about -->
	    <ul class="nav navbar-nav navbar-right">

				<li>
  				<a href="citation.html">
    				<span class="ion ion-information-circled"></span>
    		    Citation
  				</a>
				</li>
				
			
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="analysis-protocols" class="section level1 tabset tabset-pills tabset-fade">
<h1>Analysis Protocols</h1>
<p>Once you have generated the data from the MiSeq you must complete the following steps in order to analyze the data.</p>
<div id="software-requirements" class="section level2">
<h2>Software Requirements</h2>
<p>The primary software used for analysis is Mothur. This program is command line based, and will require you to type simple commands into either Terminal (Mac) or Command Prompt (Windows).</p>
<p>To download Mothur go to the Mothur github <a href="https://github.com/mothur/mothur/releases/latest">downloads</a> page and download the latest version for your operating system. Unzip then move this folder to your home directory (your C: Drive on a PC, or your ‘User’ folder on a Mac).</p>
<div class="panel panel-info">
<div class="panel-heading">
Tip
</div>
<div class="panel-body">
<p>To check that you have placed the folder in the correct location, open up either Terminal (Mac) or Command Prompt (PC). Type <code>~/mothur/mothur</code> (Mac) or <code>C:\mothur\mothur.exe</code> (PC). If your screen looks similar to this:</p>
<p><img src="images/mothur_screenshot.png" /></p>
<p>You have done it correctly.</p>
</div>
</div>
</div>
<div id="preparing-files-for-analysis" class="section level2">
<h2>Preparing files for analysis</h2>
<div id="downloading-sequencing-data-files-from-basespace" class="section level3">
<h3>Downloading sequencing data files from BaseSpace</h3>
<p>To download the sequencing fields from BaseSpace. Go to <a href="https://basespace.illumina.com/home/index" class="uri">https://basespace.illumina.com/home/index</a>, log-in, and navigate to your sequencing run. Click “Download” and select “All FASTQ files for this run”. Then click “Download your files”. BaseSpace uses the “BaseSpace Downloader” to download your files. If you have not previously downloaded this program, you must download it at this time. Select the location to download your files.</p>
<p>Once your files have downloaded, navigate to the folder where the files were downloaded. There will be one folder that corresponds to each sample that was sequenced. In each of these folders there will be two files, one that corresponds to the forward reads, and one that corresponds to the reverse reads. The forward and reverse read files for all samples will need to be moved to a single folder for analysis to conduct the analysis.</p>
<div class="panel panel-success">
<div class="panel-heading">
Recommendation
</div>
<div class="panel-body">
<p>Create a folder on your home directory with the name of your sequencing run (for the rest of this example it will be called “MiSeq_Run”). Move all of your files into this folder.</p>
</div>
</div>
<p>Once the files have been moved, the files must be unzipped/uncompressed. This can be done with the Archive Utility on a Mac and any file compression software, such as WinZip, on a PC. Make sure you unzip your files into the folder that you have created (i.e. “Miseq_Run”)</p>
</div>
<div id="create-sample-list" class="section level3">
<h3>Create sample list</h3>
<p>You will need to create a file that contains the name of your sample, and specifies which files correspond to this sample. This will tell the program which files to analyze for each particular sample. You can download the file “nemabiome.files” in the <a href="interpretation.html">Examples</a> section for an example of what this file must look like. Each line in this file represents a single sample that must be analyzed. The first column is the sample name, the second column is the file name for the forward read file, and the third column is the name of the reverse read file. Each column is separated by a single tab. An example is also listed below.</p>
<p>Example:</p>
<pre><code>sample1 sample1_S1_L001_R1_001.fastq     sample1_S1_L001_R2_001.fastq
sample2 sample2_S2_L001_R1_001.fastq     sample2_S2_L001_R2_001.fastq
sample3 sample3_S3_L001_R1_001.fastq     sample3_S3_L001_R2_001.fastq
...</code></pre>
<p>Sample names may vary between different Illumina platforms, so please check the names of your downloaded files, to ensure the file names are correct. Please name this file as “stability.files”, with the “.files” file extension. Place this file in your folder that you created for analysis. This is the only file that you will need to create from scratch for this analysis, if you use the provided files.</p>
</div>
<div id="download-analysis-files" class="section level3">
<h3>Download analysis files</h3>
<p>Download the analysis files <a href="downloads/nematode_ITS2_database_version1_3.fasta" download>Nematode ITS2 database version 1.3</a>, <a href="downloads/nematode_taxonomy_1_3.tax" download>Nematode taxonomy file (version 1.3)</a> and <a href="downloads/batchfile.txt" download>Mothur batch file</a>. Place these files in the folder that contains your sequencing data (i.e. ‘MiSeq_Run’)</p>
<p>For a standard application do not make any changes to these files. If you are aware of the number of processors that your computer has, open up the <code>batchfile.txt</code> file, go to the first line and change the parameter “processors” from “processors=2” to the number of processors in your computer.</p>
</div>
</div>
<div id="running-analysis" class="section level2">
<h2>Running analysis</h2>
<p>Once all files have been downloaded, open up Terminal or Command Prompt. You will then need to navigate to the folder you created, which can be done using the “cd” command. If you created your analysis folder in your home directory type:</p>
<pre><code>cd MiSeq_Run</code></pre>
<p>This will change to this folder.</p>
<p>Then type:</p>
<pre><code>~/mothur/mothur batchfile.txt</code></pre>
<p>(On a Mac)</p>
<p>OR</p>
<pre><code>C:\mothur\mothur.exe C:\MiSeq_Run\batchfile.txt</code></pre>
<p>(On a PC)</p>
<p>This will launch Mothur, and begin to complete the commands that are contained within the batchfile. You will need to leave your computer open and running while the analysis completes. The amount of time that it will take to run will vary with your computer, and the number of samples/reads that you will be analyzing. General run times will probably be around ~4 hours, on a standard computer, 96 samples with an average read depth of ~50,000 reads.</p>
<p>Once the analysis has completed, you will have a file called <code>nemabiome_results.summary</code>. You can open this file up and copy the contents into an Excel workbook to properly view the data.</p>
</div>
<div id="dada2-example-workflow" class="section level2">
<h2>DADA2 Example Workflow</h2>
<div id="preamble" class="section level3">
<h3>Preamble</h3>
<p>The <a href="https://benjjneb.github.io/dada2/tutorial.html">DADA2 pipeline</a> is used as a method to correct errors that are introduced into sequencing data during amplicon sequencing. The output of this pipeline is a table of amplicon sequence variants (ASVs), as opposed to the traditional OTUs seen in other amplicon sequencing workflows that cluster similar sequences into a single OTU. DADA2 is capable of resolving biological differences of 1 or 2 nucleotides, producing ASVs from amplicon data that are of higher resolution than OTUs.</p>
</div>
<div id="requirements-installations" class="section level3">
<h3>Requirements &amp; Installations</h3>
<p>DADA2 is an open-source <a href="https://github.com/benjjneb/dada2">R package</a> that will allow you to run through the entire pipeline, including steps to filter, dereplicate, identify chimeras, and merge paired-end reads.</p>
<p>To use DADA2, you must download and install R for your operating system. This can be done <a href="https://cloud.r-project.org/">here</a>. You should use the latest version of R/</p>
<p>If you would like, download and install RStudio, which is an integrated development environment (IDE) for R programming. This can be done through <a href="https://www.rstudio.com/download">this link</a>.</p>
<p>Since DADA2 is available as part of the Bioconductor Project Package Repository, install Bioconductor in R.</p>
<pre><code>install.packages(&quot;BiocManager&quot;)</code></pre>
<p>To install the latest version of the DADA2 package (1.12.1), type the following:</p>
<pre><code>BiocManager::install(&quot;dada2&quot;, version = &quot;3.9&quot;)</code></pre>
<p><em>If you have previously installed R and Bioconductor, you may need to update them to the most recent versions.</em></p>
<p>To use the DADA2 pipeline, primers must be removed from the amplicon sequence data. In the following tutorial, we will be using the <code>cutadapt</code> tool in R to do this. Cutadapt can be installed as a conda package. If you do not already have conda installed, you can do so <a href="https://docs.conda.io/en/latest/miniconda.html">here</a>. Once you have conda installed, go to Terminal or Command Prompt, and type the following:</p>
<pre><code>conda install -c bioconda cutadapt</code></pre>
</div>
<div id="dada2-workflow" class="section level3">
<h3>DADA2 Workflow</h3>
<p>Once you have installed the above, you are ready to start using the DADA2 pipeline. The following is a sample analysis using the DADA2 pipeline (<a href="https://benjjneb.github.io/dada2/tutorial.html" class="uri">https://benjjneb.github.io/dada2/tutorial.html</a>). This is meant to be an example and not a definitive workflow. First, we load packages and set a seed for reproducibility.</p>
<pre class="r"><code>library(DECIPHER)
packageVersion(&quot;DECIPHER&quot;)</code></pre>
<pre><code>## [1] &#39;2.12.0&#39;</code></pre>
<pre class="r"><code>library(dada2)
packageVersion(&quot;dada2&quot;) </code></pre>
<pre><code>## [1] &#39;1.12.1&#39;</code></pre>
<pre class="r"><code>library(ShortRead)
packageVersion(&quot;ShortRead&quot;) </code></pre>
<pre><code>## [1] &#39;1.42.0&#39;</code></pre>
<pre class="r"><code>library(Biostrings)
packageVersion(&quot;Biostrings&quot;)</code></pre>
<pre><code>## [1] &#39;2.52.0&#39;</code></pre>
<pre class="r"><code>library(ggplot2)
packageVersion(&quot;ggplot2&quot;)</code></pre>
<pre><code>## [1] &#39;3.1.1&#39;</code></pre>
<pre class="r"><code>library(stringr) # not strictly required but handy
packageVersion(&quot;stringr&quot;)</code></pre>
<pre><code>## [1] &#39;1.4.0&#39;</code></pre>
<pre class="r"><code>set.seed(106)</code></pre>
</div>
<div id="setup" class="section level3">
<h3>Setup</h3>
<p>To get started we’ll need to do a little prep. We’ll start by defining the path of sequences to be processed (using “~/Miseq_Run” from previous examples). The DADA2 pipeline is intended to be used with demultiplexed, paired-end fastq files. That is to say, the samples must be separated into individual files and ordered such that forward and reverse reads of the same sample are matched. The pattern of the filenames should be the same for all forward and reverse files. In this example, the names are formatted as such: <code>samplename_R1_001.fastq.fz</code> for forward reads and <code>samplename_R2_001.fastq.gz</code> for reverse reads.</p>
<p>We then create a vector of file names, one for the forward reads and one for the reverse. The <code>samples</code> vector contains our sample names, extracted from the file names using a regular expression. For Illumina data, often the sample name is everything before the first underscore.</p>
<p>The primer sequences are defined here as well, because we’ll be clipping those off shortly. The forward primer will be at the beginning of the forward read and the reverse primer will be at the beginning of the reverse read. The reverse complements are included in case the amplicon sequence is shorter than our read length. When this happens the sequence will contain the reverse complement of the opposite primer, i.e. there may be reverse-complemented reverse primer at the end of the forward read.</p>
<pre class="r"><code>path &lt;- &quot;~/MiSeq_Run&quot;

fwd_files &lt;- sort(list.files(path, pattern = &quot;R1&quot;, full.names = TRUE)) 
rev_files &lt;- sort(list.files(path, pattern = &quot;R2&quot;, full.names = TRUE))


# It&#39;s also handy to have a vector of sample names, which in this case is everything up 
# until the first underscore, which is what our regular expression caputres.  You may
# also create this manually if you don&#39;t have too many samples
samples = str_extract(basename(fwd_files), &quot;^[^_]+&quot;)


names(fwd_files) &lt;- samples
names(rev_files) &lt;- samples

fwd_primer &lt;- &quot;ACGTCTGGTTCAGGGTTGTT&quot;
rev_primer &lt;- &quot;TTAGTTTCTTTTCCTCCGCT&quot;
fwd_primer_rev &lt;- as.character(reverseComplement(DNAStringSet(fwd_primer)))
rev_primer_rev &lt;- as.character(reverseComplement(DNAStringSet(rev_primer)))</code></pre>
<p>Before we move on let’s do a quick sanity check to make sure our primer sequences are detected. The code below will count the number of times we have a primer hit in our fastq file. Note that this is a quick and dirty method to be sure that we have the right primer sequence. For proper primer removal we’ll need something more sophisticated, like <code>cutadapt</code> which we’ll demonstrate next.</p>
<pre class="r"><code># This function counts number of reads in which the primer is found
count_primers &lt;- function(primer, filename) {
  num_hits &lt;- vcountPattern(primer, sread(readFastq(filename)), fixed = FALSE)
  return(sum(num_hits &gt; 0))
}

count_primers(fwd_primer, fwd_files[[1]])</code></pre>
<pre><code>## [1] 25357</code></pre>
<pre class="r"><code>count_primers(rev_primer, rev_files[[1]])</code></pre>
<pre><code>## [1] 21503</code></pre>
</div>
<div id="primer-removal" class="section level3">
<h3>Primer removal</h3>
<p>Now we can use cutadapt to remove primers, and check that they have been successfully removed. Cutadapt was designed to remove sequencing adapters that sometimes get left on the reads, however, it’s main function is to detect and trim off regions that match a known sequence, which is precisely what we want to do here.</p>
<p>Cutadapt is best installed using conda (<code>conda install cutadapt</code>) and can also be used directly from the command line. Here we demonstrate how to run it directly from R using the <code>system2</code> command but the results are the same either way. The first parameter to <code>system2</code> is the program we wish to run and the second is character vector of arguments and their values.</p>
<pre class="r"><code># CHANGE ME to the cutadapt path on your machine.  If you&#39;ve installed conda according to the 
# provided instructions then this will likely be the same for you.
cutadapt &lt;- path.expand(&quot;~/miniconda3/bin/cutadapt&quot;)

# Make sure it works
system2(cutadapt, args = &quot;--version&quot;) </code></pre>
<p>Now output filenames are defined as well as parameters for cutadapt. The critical parameters are the primer sequences and their orientation. It’s strongly recommended that you review the [cutadapt documentation] (<a href="https://cutadapt.readthedocs.io/en/stable/guide.html" class="uri">https://cutadapt.readthedocs.io/en/stable/guide.html</a>) for full details of each parameter. Briefly:</p>
<p><code>-g</code>: sequence to trim off the 5’ end of the forward read (forward primer) <code>-a</code>: sequence to trim off the 3’ end of the forward read (reverse complemented reverse primer) <code>-G</code>: sequence to trim off the 5’ end of the reverse read (reverse primer) <code>-A</code>: sequence to trim off the 3’ end of the reverse read (reverse complemented forward primer)</p>
<p>We’ll also add <code>-m 50</code> to get rid of super short junky reads, <code>--max-n 1</code> to get rid of reads that have any N’s in them and <code>-n 2</code> so that cutadapt will remove multiple primer hits if there happens to be read-through. The <code>--discard-untrimmed</code> is also added so only reads that contain a primer will be kept ensuring we keep only valid amplicons. And finally a <code>-q 15</code> will trim off low quality bases from the 3’ end.</p>
<div class="alert alert-warning" role="alert">
<p>
In our experience this small amount of trimming can remove the need for truncating the reads later on but this is something that may vary from run to run it and an important paramter to consider for your own data
</p>
</div>
<pre class="r"><code># Create an output directory to store the clipped files
cut_dir &lt;- file.path(path, &quot;cutadapt&quot;)
if (!dir.exists(cut_dir)) dir.create(cut_dir)

fwd_cut &lt;- file.path(cut_dir, basename(fwd_files))
rev_cut &lt;- file.path(cut_dir, basename(rev_files))

names(fwd_cut) &lt;- samples
names(rev_cut) &lt;- samples

# It&#39;s good practice to keep some log files so let&#39;s create some
# file names that we can use for those 
cut_logs &lt;- path.expand(file.path(cut_dir, paste0(samples, &quot;.log&quot;)))

cutadapt_args &lt;- c(&quot;-g&quot;, fwd_primer, &quot;-a&quot;, rev_primer_rev, 
                   &quot;-G&quot;, rev_primer, &quot;-A&quot;, fwd_primer_rev,
                   &quot;-n&quot;, 2, &quot;--discard-untrimmed&quot;)

# Loop over the list of files, running cutadapt on each file.  If you don&#39;t have a vector of sample names or 
# don&#39;t want to keep the log files you can set stdout = &quot;&quot; to output to the console or stdout = NULL to discard
for (i in seq_along(fwd_files)) {
  system2(cutadapt, 
          args = c(cutadapt_args,
                   &quot;-o&quot;, fwd_cut[i], &quot;-p&quot;, rev_cut[i], 
                   fwd_files[i], rev_files[i]),
          stdout = cut_logs[i])  
}

# quick check that we got something
head(list.files(cut_dir))</code></pre>
<pre><code>## [1] &quot;G1_S1_L001_R1_001.fastq.gz&quot; &quot;G1_S1_L001_R2_001.fastq.gz&quot;
## [3] &quot;G1.log&quot;                     &quot;G2_S2_L001_R1_001.fastq.gz&quot;
## [5] &quot;G2_S2_L001_R2_001.fastq.gz&quot; &quot;G2.log&quot;</code></pre>
</div>
<div id="inspect-quality-scores" class="section level3">
<h3>Inspect quality scores</h3>
<p>Now that primers are removed, we can begin the DADA2 pipeline in full. We start with plotting quality profiles of our sequences to determine suitable quality filtering parameters. For the sake of speed we only show 2 samples here but feel free to look at all your samples (or more than 2 anyway).</p>
<pre class="r"><code>plotQualityProfile(fwd_cut[1:2]) + ggtitle(&quot;Forward&quot;)</code></pre>
<p><img src="analysis_files/figure-html/quality_profiles-1.png" width="672" /></p>
<p>Everything looks pretty good here. The majority of our reads should be 230 bp based on the fact that we trimmed 20 bp primers off the beginning of the read. It looks like a very, very few did not get trimmed properly but from the red line across the bottom, which is the number of reads of that length, we can see that this is such a small percentage that we don’t need to worry about it.</p>
<div class="alert alert-success" role="alert">
<h4 class="alert-heading">
Side note
</h4>
<p>
If you’re paying attention you might be asking why, if the primers always appear at the same point in the read, can’t we just clip the reads at this point. In fact, for some datasets, this one included, that would be a valid strategy given that the all the ITS2 sequences are longer than the read length (250 bp). However, this is not always the case and as described above, if the amplicon length is less than the read lenght we’ll have to find and remove the opposite primer. So in general it’s good practice to use something like cutadapt which will ensure the correct sequences are output.
</p>
</div>
<pre class="r"><code>plotQualityProfile(rev_cut[1:2]) + ggtitle(&quot;Reverse&quot;)</code></pre>
<p><img src="analysis_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Reverse reads are lower quality as is always the case for Illumina data. However, it looks like the quality average is above 20 for most of the length of the read so we’ll go ahead with the analysis.</p>
</div>
<div id="quality-filtering" class="section level3">
<h3>Quality filtering</h3>
<p>For the purposes of our analysis, we chose to conduct quality filtering with maximum expected errors of 2 for the forward sequence, 5 for the reverse, to truncate after a quality score of 2 or lower.</p>
<div class="alert alert-warning" role="alert">
<p>
Make your own decisions about trimming paramters! Your data will be different, possibly very different, from ours so our parmeter choices are likely to be not at all appropriate for your data. So don’t copy and paste this code - think carefully about your data and choose parameters appropriate for your data.
</p>
</div>
<pre class="r"><code># Same as for the clippling we create an output directory to store the filtered files
filt_dir &lt;- file.path(path, &quot;filtered&quot;)
if (!dir.exists(filt_dir)) dir.create(filt_dir)

fwd_filt &lt;- file.path(filt_dir, basename(fwd_files))
rev_filt &lt;- file.path(filt_dir, basename(rev_files))

names(fwd_filt) &lt;- samples
names(rev_filt) &lt;- samples

filtered_out &lt;- filterAndTrim(
  fwd = fwd_cut, 
  filt = fwd_filt,
  rev = rev_cut,
  filt.rev = rev_filt,
  maxEE = c(2, 5), 
  truncQ = 2, 
  rm.phix = TRUE, 
  compress = TRUE, 
  multithread = TRUE
  )  

head(filtered_out)</code></pre>
<pre><code>##                            reads.in reads.out
## G1_S1_L001_R1_001.fastq.gz    25276     24107
## G2_S2_L001_R1_001.fastq.gz    25908     24533</code></pre>
</div>
<div id="main-dada2-workflow" class="section level3">
<h3>Main dada2 workflow</h3>
<p>Much of the remainder of the dada2 workflow is very well documented in the main dada2 tutorial so if you’d like to read in more detail please that tutorial as well as the dada2 paper.</p>
<div id="learn-errors" class="section level4">
<h4>Learn errors</h4>
<p>Here dada2 learns the error profile for your data using an interative approach. These error profiles are used in the next step to correct errors.</p>
<pre class="r"><code>err_fwd &lt;- learnErrors(fwd_filt, multithread = TRUE)</code></pre>
<pre><code>## 11162461 total bases in 48640 reads from 2 samples will be used for learning the error rates.</code></pre>
<pre class="r"><code>err_rev &lt;- learnErrors(rev_filt, multithread = TRUE)</code></pre>
<pre><code>## 11118332 total bases in 48640 reads from 2 samples will be used for learning the error rates.</code></pre>
<pre class="r"><code>plotErrors(err_fwd, nominalQ = TRUE)</code></pre>
<p><img src="analysis_files/figure-html/unnamed-chunk-6-1.png" width="672" /> The plot shows how well the estimated error rates fit the observed rates. The black line should line up reasonably well with the black points. This looks reasonable so we continue on.</p>
</div>
<div id="denoising-aka-error-correcting" class="section level4">
<h4>Denoising (aka error-correcting)</h4>
<p>We can now denoise our sequences using the DADA algorithm. Note that older versions of dada2 required a dereplication step that is now done automatically by the <code>dada</code> function.</p>
<pre class="r"><code>dada_fwd &lt;- dada(fwd_filt, err = err_fwd, multithread = TRUE)</code></pre>
<pre><code>## Sample 1 - 24107 reads in 4939 unique sequences.
## Sample 2 - 24533 reads in 5379 unique sequences.</code></pre>
<pre class="r"><code>dada_rev &lt;- dada(rev_filt, err = err_rev, multithread = TRUE)</code></pre>
<pre><code>## Sample 1 - 24107 reads in 15358 unique sequences.
## Sample 2 - 24533 reads in 15463 unique sequences.</code></pre>
</div>
<div id="merge-pairs" class="section level4">
<h4>Merge pairs</h4>
<p>Now that we have accurate sequences we can merge the paired-end reads to reconstruct the full amplicon sequence. Note that most sequences should succesfully overlap, <em>unless</em> your trimming parameters were too aggresive (i.e. too much sequence was trimmed off the end) <em>or</em> you have amplicons that longer than the combined read length (&gt;500 bp, in this case). In the latter case these reads are still useable but will need special handling (more details to come on those cases).</p>
<pre class="r"><code>mergers &lt;- mergePairs(
  dadaF = dada_fwd,
  dadaR = dada_rev,
  derepF = fwd_filt,
  derepR = rev_filt,
  maxMismatch = 1, 
  verbose=TRUE
)</code></pre>
</div>
<div id="sequence-table" class="section level4">
<h4>Sequence table</h4>
<p>Before we can assign taxonomy, we can construct a sequence table, which lists the number of each sequence present in each sample. We can see the dimensions of this sequence table, where the number of rows is the number of samples and the number of columns is the number of total unique sequences</p>
<pre class="r"><code>seqtab &lt;- makeSequenceTable(mergers)
dim(seqtab) </code></pre>
<pre><code>## [1]  2 55</code></pre>
</div>
<div id="remove-chimeras" class="section level4">
<h4>Remove chimeras</h4>
<p>Don’t be alarmed here if many of your sequences are discarded - the number of chimeras varies but can be quite high in some cases.</p>
<pre class="r"><code>seqtab_nochim &lt;- removeBimeraDenovo(seqtab, method = &quot;consensus&quot;, multithread = TRUE, verbose = TRUE)
dim(seqtab_nochim)</code></pre>
<pre><code>## [1]  2 19</code></pre>
</div>
</div>
<div id="how-did-we-do" class="section level3">
<h3>How did we do?</h3>
<div id="sequence-length-distribution" class="section level4">
<h4>Sequence length distribution</h4>
<pre class="r"><code>table(nchar(getSequences(seqtab_nochim)))</code></pre>
<pre><code>## 
## 273 274 281 283 287 288 289 291 
##   2   2   2   2   2   1   1   7</code></pre>
</div>
<div id="number-of-reads-at-each-step" class="section level4">
<h4>Number of reads at each step</h4>
<p>This is an important step, particularly if you’re trying to track down where something went wrong.</p>
<pre class="r"><code># small function to get the number of sequences
getN &lt;- function(x) sum(getUniques(x))

track &lt;- cbind(
  filtered_out, 
  sapply(dada_fwd, getN), 
  sapply(dada_rev, getN), 
  sapply(mergers, getN), 
  rowSums(seqtab_nochim)
)

colnames(track) &lt;- c(&quot;raw&quot;, &quot;filtered&quot;, &quot;denoised_fwd&quot;, &quot;denoised_rev&quot;, &quot;merged&quot;, &quot;no_chim&quot;)
rownames(track) &lt;- samples  
head(track)</code></pre>
<pre><code>##      raw filtered denoised_fwd denoised_rev merged no_chim
## G1 25276    24107        24071        21484  21286   20336
## G2 25908    24533        24479        21994  21684   19950</code></pre>
</div>
</div>
<div id="assigning-taxonomy-with-idtaxa" class="section level3">
<h3>Assigning taxonomy with IDTAXA</h3>
<p>Now that we have a sequence table with the chimeras removed, we can classify/assign taxonomy to the sequence variants. Although there are multiple multiple taxonomic classification methods, we will be using IdTaxa, which is available through the <code>DECIPHER</code> package. You can read more about IdTaxa <a href="https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-018-0521-5">here</a>.</p>
<div id="training-the-classifier" class="section level4">
<h4>Training the classifier</h4>
<p>The IdTaxa classification method relies on a training set that contains sequences that are representative of known taxa. Although there exists trained classifiers, we will be using the ITS2 Nematode database as our classifier. Since it is not trained, we will have to train the classifier using <code>LearnTaxa</code>, which is also available as a <code>DECIPHER</code> package. The <code>train</code> parameter of <code>LearnTaxa</code> contains the sequences included in the classifier as a DNAStringSet. Each sequence is formatted such that the names of each taxonomic level is separated by a semicolon. Once the sequence headers of the classifier are parsed, the <code>taxonomy</code> parameter will contain the taxonomic assignment, separated by a semicolon, for each sequence in <code>train</code>.</p>
<pre class="r"><code># Load the sequences (we use the rdp formatted database here - the IDTAXA formatted version will be forthcoming)
train &lt;- readDNAStringSet(&quot;~/Nematode_ITS2_rdp_0.9.3.fasta&quot;)

# extract the sequence headers and remove everything up to and including the first space
# this is the format required by the classifier
taxonomy &lt;- names(train)
taxonomy = str_remove(taxonomy, &quot;^[\\S]+\\s&quot;)

# Train the classifier
trainingSet &lt;- LearnTaxa(train, taxonomy)</code></pre>
<pre><code>## ===========================================================================
## 
## Time difference of 11.07 secs</code></pre>
</div>
<div id="running-idtaxa" class="section level4">
<h4>Running IdTaxa</h4>
<p>To use IdTaxa, we will need to convert the unique sequence variants that we want to classify into a DNAStringSet object. Now that we have our trained classifier (i.e. training set) and the sequences we want to classify, we can run <code>IdTaxa</code>. You can change various parameters of <code>IdTaxa</code> depending on your data. We recommend reviewing the [IdTaxa documentation] (<a href="https://rdrr.io/bioc/DECIPHER/man/IdTaxa.html" class="uri">https://rdrr.io/bioc/DECIPHER/man/IdTaxa.html</a>) for further information. Here, we have specified several parameters:</p>
<ul>
<li><code>strand = &quot;both&quot;</code> : by setting the <code>strand</code> parameter to “both”, each sequence variant is classified using both the forward and reverse complement orientation. The sequence varient will be classified as the result with the highest confidence.</li>
<li><code>threshold = 60</code> : setting the <code>threshold</code> to 60 specifies when the taxonomic classifications are truncated. A lower threshold usually results in higher taxonomic level classifications, but lower accuracy (i.e. confidence). A higher threshold usually results in lower taxonomic level classifications, but with higher accuracy.</li>
<li><code>bootstraps = 100</code> : this specifies the amount of times bootstrap replicates are performed for each sequence.</li>
<li><code>processors = NULL</code> : automatically uses all available processors.</li>
<li><code>verbose = TRUE</code> : displays progress.</li>
<li><code>type = &quot;extended&quot;</code> : by setting the <code>type</code> to “extended”, the output for each sequence variant will contain the taxonomic classification, the names of each taxonomic rank, and the confidence of the assignment.</li>
</ul>
<pre class="r"><code>dna &lt;- DNAStringSet(getSequences(seqtab_nochim))

idtaxa &lt;- IdTaxa(dna, 
              trainingSet, 
              strand = &quot;both&quot;, 
              threshold = 60, 
              bootstraps = 100, 
              processors = NULL, 
              verbose = TRUE, 
              type = &quot;extended&quot;)</code></pre>
<pre><code>## ===========================================================================
## 
## Time difference of 0.62 secs</code></pre>
<p>Although it contains all the necessary information, the output of <code>IdTaxa</code> is not as intuitive as we would like. It outputs a list of the sequence variants. Within this list, each element will have its taxonomic classification and the confidence for each taxon. To facilitate easier manipulation and comprehension of the data, we will convert this list into a matrix, with the rows as the sequence variants and the columns as their taxonomic classifications.</p>
<pre class="r"><code># These are the ranks in the Nematode ITS2 database
ranks &lt;- c(&quot;superkingdom&quot;, &quot;kingdom&quot;, &quot;phylum&quot;, &quot;class&quot;, &quot;order&quot;, &quot;family&quot;, &quot;genus&quot;, &quot;species&quot;)

# Extract the classification and remove the &quot;Root&quot; column
taxid &lt;- t(sapply(idtaxa, function(x) x$taxon))[,-1]

# column bnames are the ranks, and rownames should match the column names of the sequence table
colnames(taxid) &lt;- ranks
rownames(taxid) &lt;- colnames(seqtab_nochim)</code></pre>
</div>
</div>
<div id="over-to-phyloseq" class="section level3">
<h3>Over to phyloseq</h3>
<pre class="r"><code>library(phyloseq)
# This is just a placeholder - normally this would be a dataframe containing all your sample inforamtion,
# with rownames matching the sample names
samp_data &lt;-  data.frame(
  row.names = samples,
  sample = samples
)

# We need better tables for our sequences than the actual sequence which is the dada2 default
asvs &lt;- paste0(&quot;ASV_&quot;, 1:length(dna))
rownames(taxid) &lt;- asvs
colnames(seqtab_nochim) &lt;- asvs
names(dna) &lt;- asvs

# Now we put everything into one phyloseq object (even the sequences) so it is easy to use
physeq = phyloseq(
  otu_table(seqtab_nochim, taxa_are_rows = FALSE),
  tax_table(taxid),
  sample_data(samp_data),
  dna
)

physeq</code></pre>
<pre><code>## phyloseq-class experiment-level object
## otu_table()   OTU Table:         [ 19 taxa and 2 samples ]
## sample_data() Sample Data:       [ 2 samples by 1 sample variables ]
## tax_table()   Taxonomy Table:    [ 19 taxa by 8 taxonomic ranks ]
## refseq()      DNAStringSet:      [ 19 reference sequences ]</code></pre>
</div>
</div>
<div id="downloads" class="section level2">
<h2>Download list</h2>
<ul>
<li><a href="downloads/batchfile.txt" download="downloads/batchfile.txt">Mothur batch file</a></li>
<li><a href="downloads/nematode_taxonomy_1_3.tax" download>Nematode taxonomy file (version 1.3)</a></li>
<li><a href="downloads/nematode_ITS2_database_version1_3.fasta" download>Nematode ITS2 database version 1.3</a></li>
</ul>
</div>
</div>

   </div> <!-- articleBandContent -->
</div> <!-- pageContent -->
 

<footer class="footer">
	<nav class="navbar navbar-default navbar-fixed-bottom">
	  <div class="container">
	    <div class="col-sm-12 text-center navbar-text">
	        <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
    				<img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" />
    		</a>
    		This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
	    </div>
	  </div>
	</nav>
</footer>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
